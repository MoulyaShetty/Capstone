{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T06:52:36.170300Z","iopub.status.busy":"2023-11-07T06:52:36.169562Z","iopub.status.idle":"2023-11-07T06:52:36.443457Z","shell.execute_reply":"2023-11-07T06:52:36.442382Z","shell.execute_reply.started":"2023-11-07T06:52:36.170261Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.98      0.98      0.98        66\n","           1       0.98      0.98      0.98        50\n","           2       1.00      1.00      1.00        59\n","\n","    accuracy                           0.99       175\n","   macro avg       0.99      0.99      0.99       175\n","weighted avg       0.99      0.99      0.99       175\n","\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","import cv2\n","import mediapipe as mp\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image as keras_image\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","import joblib\n","# Load the CSV files\n","correct_df = pd.read_csv('squat/correct.csv')\n","too_high_df = pd.read_csv('squat/too_high.csv')\n","too_low_df = pd.read_csv('squat/too_low.csv')\n","\n","# Add a label column to each dataframe\n","correct_df['label'] = 'correct'\n","too_high_df['label'] = 'too_high'\n","too_low_df['label'] = 'too_low'\n","\n","# Combine the dataframes\n","data_df = pd.concat([correct_df, too_high_df, too_low_df])\n","\n","# Shuffle the combined dataframe\n","data_df = data_df.sample(frac=1).reset_index(drop=True)\n","\n","# Split the data into features and labels\n","X = data_df.drop(['label', 'image_id'], axis=1)  # Assuming all other columns are features\n","y = data_df['label']\n","\n","# Encode the labels to integers\n","y = y.map({'correct': 0, 'too_high': 1, 'too_low': 2})\n","\n","# Split the data into a training set and a test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize the RandomForestClassifier\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","\n","\n","# Train the model\n","model.fit(X_train, y_train)\n","joblib.dump(model, \"new_model.h5\")\n","# Predict on the test set\n","y_pred = model.predict(X_test)\n","\n","# Evaluate the model\n","print(classification_report(y_test, y_pred))\n","\n","# Use the trained model to make predictions on new data\n","def predict_new_data(new_data):\n","    # new_data should be a dataframe with the same structure as the training data\n","    new_prediction = model.predict(new_data)\n","    return new_prediction\n","\n","# Example of using the function\n","# new_data = pd.DataFrame({'angle': [new_angle]})\n","# prediction = predict_new_data(new_data)\n","# print(prediction)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2\n","import mediapipe as mp\n","import numpy as np\n","import pandas as pd\n","import joblib\n","\n","# Load the trained RandomForest model\n","model = joblib.load(\"new_model.h5\")\n","\n","# Define a dictionary to convert model output to human-readable labels\n","label_dict = {0: \"Correct\", 1: \"Too High\", 2: \"Too Low\"}\n","\n","# Initialize mediapipe pose class\n","mp_pose = mp.solutions.pose\n","pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n","\n","# Initialize the video capture object\n","cap = cv2.VideoCapture(0)  # 0 is typically the built-in webcam\n","\n","frame_count = 0\n","frame_skip = 9  # this will process every 10th frame\n","\n","try:\n","    while cap.isOpened():\n","        success, image = cap.read()\n","        if not success:\n","            print(\"Ignoring empty camera frame.\")\n","            continue  # skip empty frames\n","\n","        # Skip frames to process every 10th frame\n","        frame_count += 1\n","        if frame_count % (frame_skip + 1) != 0:\n","            continue\n","\n","        # Convert the BGR image to RGB\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        # Perform pose detection\n","        results = pose.process(image)\n","\n","        # Draw pose annotations on the image\n","        mp_drawing = mp.solutions.drawing_utils\n","        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n","\n","        # Calculate the squat angle if pose landmarks are detected\n","        if results.pose_landmarks:\n","            # Extract landmarks\n","            landmarks = results.pose_landmarks.landmark\n","            try:\n","                hip = np.array([landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n","                                landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y])\n","                knee = np.array([landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n","                                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y])\n","                ankle = np.array([landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n","                                  landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y])\n","                # Calculate the angle using arccos\n","                angle = np.arccos(np.dot((hip - knee), (ankle - knee)) /\n","                                  (np.linalg.norm(hip - knee) * np.linalg.norm(ankle - knee)))\n","                angle = np.degrees(angle)\n","\n","                # Prepare the angle data for prediction\n","                new_data = pd.DataFrame({'angle': [angle]})\n","                prediction = model.predict(new_data)\n","                squat_label = label_dict[prediction[0]]\n","                \n","                # Print the squat label to the terminal\n","                print(f'Squat label: {squat_label}')\n","                \n","                # Display the prediction on the frame\n","                cv2.rectangle(image, (5, 5), (300, 60), (0, 0, 0), -1)  # Adds a black rectangle as a background for the text\n","                cv2.putText(image, f'Squat: {squat_label}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n","            except Exception as e:\n","                # Print any exceptions to the terminal\n","                print(e)\n","                pass  # If there is any error in the landmark detection, ignore it\n","\n","        # Convert the RGB image back to BGR\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","\n","        # Display the resulting frame\n","        cv2.imshow('Squat Posture Evaluation', image)\n","\n","        # Press 'q' to break out of the loop\n","        if cv2.waitKey(5) & 0xFF == ord('q'):\n","            break\n","finally:\n","    # When everything is done, release the capture\n","    cap.release()\n","    cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing complete.\n"]}],"source":["import cv2\n","import mediapipe as mp\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","# Initialize MediaPipe Pose solution\n","mp_pose = mp.solutions.pose\n","pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n","\n","# Function to calculate angle between three points using arccos\n","def calculate_angle(a, b, c):\n","    a = np.array(a)  # First\n","    b = np.array(b)  # Mid\n","    c = np.array(c)  # End\n","\n","    radians = np.arccos(np.dot((b - a), (b - c)) / (np.linalg.norm(b - a) * np.linalg.norm(b - c)))\n","    angle = np.degrees(radians)\n","\n","    return angle\n","\n","# Function to annotate image with keypoints and angles\n","def annotate_image(image, landmarks, knee_angle, hip_angle):\n","    annotated_image = image.copy()\n","    mp_drawing = mp.solutions.drawing_utils\n","    mp_drawing.draw_landmarks(annotated_image, landmarks, mp_pose.POSE_CONNECTIONS)\n","    cv2.putText(annotated_image, f'Knee Angle: {int(knee_angle)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n","    cv2.putText(annotated_image, f'Hip Angle: {int(hip_angle)}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n","    return annotated_image\n","\n","# Directories containing images\n","directories = ['correct', 'too_high', 'too_low']\n","\n","# Process each directory\n","for folder in directories:\n","    data = []\n","    for filename in os.listdir(folder):\n","        if filename.endswith('.jpg') or filename.endswith('.png'):\n","            image = cv2.imread(f'{folder}/{filename}')\n","            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","            results = pose.process(image_rgb)\n","\n","            if results.pose_landmarks and results.pose_landmarks.landmark:\n","                landmarks = results.pose_landmarks.landmark\n","\n","                # Extract landmarks for the knee angle\n","                hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n","                       landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n","                knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n","                        landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n","                ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n","                         landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n","                knee_angle = calculate_angle(hip, knee, ankle)\n","\n","                # Extract landmarks for the hip angle\n","                shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n","                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n","                hip_angle = calculate_angle(shoulder, hip, knee)\n","\n","                # Annotate image\n","                annotated_image = annotate_image(image, results.pose_landmarks, knee_angle, hip_angle)\n","                cv2.imwrite(f'{folder}/annotated_{filename}', annotated_image)\n","                data.append({'Image': filename, 'Knee Angle': knee_angle, 'Hip Angle': hip_angle})\n","\n","    # Write data to CSV\n","    df = pd.DataFrame(data)\n","    df.to_csv(f'{folder}_angles.csv', index=False)\n","\n","print(\"Processing complete.\")\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99        55\n","           1       1.00      0.98      0.99        51\n","           2       1.00      1.00      1.00        69\n","\n","    accuracy                           0.99       175\n","   macro avg       0.99      0.99      0.99       175\n","weighted avg       0.99      0.99      0.99       175\n","\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","import joblib\n","\n","# Load the CSV files\n","correct_df = pd.read_csv('./correct_angles.csv')\n","too_high_df = pd.read_csv('./too_high_angles.csv')\n","too_low_df = pd.read_csv('./too_low_angles.csv')\n","\n","# Add a label column to each dataframe\n","correct_df['label'] = 'correct'\n","too_high_df['label'] = 'too_high'\n","too_low_df['label'] = 'too_low'\n","\n","# Combine the dataframes\n","data_df = pd.concat([correct_df, too_high_df, too_low_df])\n","\n","# Shuffle the combined dataframe\n","data_df = data_df.sample(frac=1).reset_index(drop=True)\n","\n","# Split the data into features and labels\n","# Assuming that 'Knee Angle' and 'Hip Angle' are the column names for angles in your CSV\n","X = data_df[['Knee Angle', 'Hip Angle']]  # Only include knee and hip angles as features\n","y = data_df['label']\n","\n","# Encode the labels to integers\n","y = y.map({'correct': 0, 'too_high': 1, 'too_low': 2})\n","\n","# Split the data into a training set and a test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize the RandomForestClassifier\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","# Train the model\n","model.fit(X_train, y_train)\n","\n","# Save the trained model\n","joblib.dump(model, \"new_model_withhip.h5\")\n","\n","# Predict on the test set\n","y_pred = model.predict(X_test)\n","\n","# Evaluate the model\n","print(classification_report(y_test, y_pred))\n","\n","# Function to predict new data\n","def predict_new_data(new_data):\n","    # Load the trained model\n","    loaded_model = joblib.load(\"new_model.h5\")\n","    # Predict using the model\n","    new_prediction = loaded_model.predict(new_data)\n","    return new_prediction\n","\n","# Example of how to use the function\n","# new_data = pd.DataFrame({'Knee Angle': [new_knee_angle], 'Hip Angle': [new_hip_angle]})\n","# prediction = predict_new_data(new_data)\n","# print(prediction)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2\n","import mediapipe as mp\n","import numpy as np\n","import pandas as pd\n","import joblib\n","\n","# Load the trained RandomForest model\n","model = joblib.load(\"new_model.h5\")\n","\n","# Define a dictionary to convert model output to human-readable labels\n","label_dict = {0: \"Correct\", 1: \"Too High\", 2: \"Too Low\"}\n","\n","# Initialize mediapipe pose class\n","mp_pose = mp.solutions.pose\n","pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n","\n","# Initialize the video capture object\n","cap = cv2.VideoCapture(0)  # 0 is typically the built-in webcam\n","\n","frame_count = 0\n","frame_skip = 9  # this will process every 10th frame\n","\n","try:\n","    while cap.isOpened():\n","        success, image = cap.read()\n","        if not success:\n","            print(\"Ignoring empty camera frame.\")\n","            continue  # skip empty frames\n","\n","        # Skip frames to process every 10th frame\n","        frame_count += 1\n","        if frame_count % (frame_skip + 1) != 0:\n","            continue\n","\n","        # Convert the BGR image to RGB\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        # Perform pose detection\n","        results = pose.process(image)\n","\n","        # Draw pose annotations on the image\n","        mp_drawing = mp.solutions.drawing_utils\n","        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n","\n","        # Calculate the squat angles if pose landmarks are detected\n","        if results.pose_landmarks:\n","            # Extract landmarks\n","            landmarks = results.pose_landmarks.landmark\n","            try:\n","                # Calculate knee angle\n","                knee_hip = np.array([landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n","                                     landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y])\n","                knee_knee = np.array([landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n","                                      landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y])\n","                knee_ankle = np.array([landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n","                                       landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y])\n","                knee_angle = np.arccos(np.dot((knee_hip - knee_knee), (knee_ankle - knee_knee)) /\n","                                       (np.linalg.norm(knee_hip - knee_knee) * np.linalg.norm(knee_ankle - knee_knee)))\n","                knee_angle = np.degrees(knee_angle)\n","\n","                # Calculate hip angle\n","                hip_shoulder = np.array([landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n","                                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y])\n","                hip_hip = np.array([landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n","                                    landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y])\n","                hip_knee = np.array([landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n","                                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y])\n","                hip_angle = np.arccos(np.dot((hip_shoulder - hip_hip), (hip_knee - hip_hip)) /\n","                                      (np.linalg.norm(hip_shoulder - hip_hip) * np.linalg.norm(hip_knee - hip_hip)))\n","                hip_angle = np.degrees(hip_angle)\n","\n","                # Prepare the data for prediction\n","                new_data_knee = pd.DataFrame({'Knee Angle': [knee_angle], 'Hip Angle': [0]})  # Dummy value for hip angle\n","                new_data_hip = pd.DataFrame({'Knee Angle': [0], 'Hip Angle': [hip_angle]})  # Dummy value for knee angle\n","\n","                # Predict the posture\n","                knee_prediction = model.predict(new_data_knee)\n","                hip_prediction = model.predict(new_data_hip)\n","\n","                # Get labels for knee and hip\n","                knee_label = label_dict[knee_prediction[0]]\n","                hip_label = label_dict[hip_prediction[0]]\n","                \n","                # Display the predictions on the frame\n","                                # Display the predictions on the frame\n","                cv2.rectangle(image, (5, 5), (300, 90), (0, 0, 0), -1)  # Adds a black rectangle as a background for the text\n","                cv2.putText(image, f'Knee: {knee_label}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n","                cv2.putText(image, f'Hip: {hip_label}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n","\n","            except Exception as e:\n","                # Print any exceptions to the terminal\n","                print(e)\n","                pass  # If there is any error in the landmark detection, ignore it\n","\n","        # Convert the RGB image back to BGR\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","\n","        # Display the resulting frame\n","        cv2.imshow('Squat Posture Evaluation', image)\n","\n","        # Press 'q' to break out of the loop\n","        if cv2.waitKey(5) & 0xFF == ord('q'):\n","            break\n","finally:\n","    # When everything is done, release the capture\n","    cap.release()\n","    cv2.destroyAllWindows()\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":4}
